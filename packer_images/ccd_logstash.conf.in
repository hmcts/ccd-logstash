input {
    jdbc {
        # CCD conf
        jdbc_connection_string => "${DB_URL}"
        jdbc_user => "${DB_USER}"
        jdbc_password => "${DB_PWD}"
        jdbc_validate_connection => true
        jdbc_driver_library => "/usr/share/logstash/postgresql-42.2.2.jar"
        jdbc_driver_class => "org.postgresql.Driver"

        jdbc_page_size => "20000"
        jdbc_default_timezone => "UTC"

        use_column_value => false

        parameters => {
                        "divorcej" => "DIVORCE"
                        "cmcj" => "CMC"
                        "probatej" => "PROBATE"
                        "ethosj" => "EMPLOYMENT"
                        "sscsj" => "SSCS"
                      }

        statement => "UPDATE case_data SET marked_by_logstash = true WHERE marked_by_logstash = false AND jurisdiction != :divorcej AND jurisdiction != :cmcj AND jurisdiction != :probatej AND jurisdiction != :sscsj AND jurisdiction != :ethosj RETURNING id, created_date, last_modified, jurisdiction, case_type_id, state, last_state_modified_date, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification, supplementary_data::TEXT as json_supplementary_data"

    	clean_run => false
    	last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run_ccd"
	    
	    # every second
        schedule => "* * * * * *"
	    # every 2 seconds
        # schedule => "/2 * * * * *"
    }
}

filter{
	json{
		source => "json_data"
		target => "data"
		remove_field => ["json_data"]
	}
	json{
		source => "json_data_classification"
		target => "data_classification"
		remove_field => ["json_data_classification"]
	}
	json{
    	source => "json_supplementary_data"
    	target => "supplementary_data"
    	remove_field => ["json_supplementary_data"]
    }

    json{
    	source => "[data][SearchCriteria][SearchParties]"
    	target => "[data][SearchCriteria][SearchParties]"
    }

    if [data][SearchCriteria][SearchParties] {
            mutate {
                 add_field => {"test_SearchParties" => "%{[data][SearchCriteria][SearchParties]}" }
        }
    }


    if [data][SearchCriteria][OtherCaseReferences] {
       mutate {
             add_field => {"test_OtherCaseReferences" => "%{[data][SearchCriteria][OtherCaseReferences]}" }
       }
    }

    if [supplementary_data][HMCTSServiceId] {
        mutate {
           add_field => {"test_HMCTSServiceId" => "%{[supplementary_data][HMCTSServiceId]}" }
        }
    }

    if [data][caseNameHmctsInternal] {
       mutate {
           add_field => {"test_caseNameHmctsInternal" => "%{[data][caseNameHmctsInternal]}" }
       }
    }

    if [data][caseManagementLocation][region] {
       mutate {
         add_field => {"test_region" => "%{[data][caseManagementLocation][region]}" }
       }
     }

     if [data][caseManagementLocation][baseLocation] {
           mutate {
                add_field => {"test_baseLocation" => "%{[data][caseManagementLocation][baseLocation]}" }
         }
    }

    # mutate { remove_field => [ "@timestamp", "@version" ] }
	mutate {
    	add_field => {
    	    "index_id" => "%{case_type_id}_cases"
           }
  	}
	mutate {
		lowercase => [ "index_id" ]
	}
}

#TODO future releases of ES will use _doc as mapping type. When LS sets _doc as the default type, remove 'document_type'
output {
    elasticsearch {
        hosts => ["${ES_DATA_NODES_URL}"]
        sniffing => false
        index => "%{[index_id]}"
        document_type => "_doc"
        document_id => "%{id}"
        timeout => 60
    }
}
