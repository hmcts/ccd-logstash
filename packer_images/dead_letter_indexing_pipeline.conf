input {
  dead_letter_queue {
    path => "/var/lib/logstash/dead_letter_queue"
    commit_offsets => true
    pipeline_id => "main"
  }
}

filter {
  # First, we must capture the entire event, and write it to a new
  # field; we'll call that field `failed_message`
  ruby {
    code => "event.set('failed_message', event.to_json())"
  }

  # Next, we prune every field off the event except for the one we've
  # just created. Note that this does not prune event metadata.
  prune {
    whitelist_names => [ "^failed_message$" ]
  }

  # Next, convert the metadata timestamp to one we can parse with a
  # date filter. Before conversion, this field is a Logstash::Timestamp.
  # http://www.rubydoc.info/gems/logstash-core/LogStash/Timestamp
  ruby {
    code => "event.set('timestamp', event.get('[@metadata][dead_letter_queue][entry_time]').toString())"
  }

  # Apply the date filter.
  date {
    match => [ "timestamp", "ISO8601" ]
  }

  ruby {
    code => "event.set('case_type', event.get('[case_type_id]'))"
  }

  ruby {
    code => "event.set('case_last_modified', event.get('[last_modified]'))"
  }

  # Pull useful information out of the event metadata provided by the dead
  # letter queue, and add it to the new event.
  mutate {
    add_field => {
      "reason" => "%{[@metadata][dead_letter_queue][reason]}"
    }
  }
}

output {
  elasticsearch {
    hosts => ["ES_URL:9200"]
    sniffing => false
    index => ".logstash_dead_letter"
  }
}
