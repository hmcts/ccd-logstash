input {
    jdbc {
        # Postgres jdbc connection string to our database, mydb
        jdbc_connection_string => "jdbc:postgresql://ccd-data-store-api-postgres-db-sandbox.postgres.database.azure.com:5432/ccd_data_store?ssl=true"
        # The user we wish to execute our statement as
        jdbc_user => "ccd@ccd-data-store-api-postgres-db-sandbox"
        jdbc_password => "U>MaA<1FT{j-ZIEB"
        jdbc_validate_connection => true
        # The path to our downloaded jdbc driver
        jdbc_driver_library => "/usr/share/logstash/postgresql-42.2.2.jar"
        # The name of the driver class for Postgresql
        jdbc_driver_class => "org.postgresql.Driver"
        # our query

        #statement => "SELECT id, created_date, last_modified, jurisdiction, case_type_id, state, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification from case_data where id=1"

        jdbc_paging_enabled => "true"
	    jdbc_page_size => "1000"
	             
		statement => "SELECT id, created_date, last_modified, jurisdiction, case_type_id, state, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification from case_data where id > :sql_last_value"
    	use_column_value => true
        tracking_column => "id"
    	tracking_column_type => "numeric"
    	clean_run => false
			# FIXME if we store on the logstash vm, we lose it if the vm is recreated
    	last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run"
	    
	    # every second
			schedule => "* * * * * *"
	    # every 2 seconds
			# schedule => "/2 * * * * *"
    }
}

filter{
	json{
		source => "json_data"
		target => "data"
		remove_field => ["json_data"]
	}
	json{
		source => "json_data_classification"
		target => "data_classification"
		remove_field => ["json_data_classification"]
	}
	# mutate { remove_field => [ "@timestamp", "@version" ] }
	mutate {
    	add_field => { "index_id" => "%{case_type_id}_cases" }
  	}
	mutate {
		lowercase => [ "index_id" ]
	}
}

#FIXME document_type is deprecated
output {
    elasticsearch {
			hosts => ["10.112.0.4:9200"]
			sniffing => false
			index => "%{[index_id]}"
			document_type => "case"
			document_id => "%{id}"
    }
}
