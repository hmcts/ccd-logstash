input {
    jdbc {
			# Postgres jdbc connection string to our database, mydb
			jdbc_connection_string => "DB_URL"
			# The user we wish to execute our statement as
			jdbc_user => "DB_USER"
			jdbc_password => "DB_PWD"
			jdbc_validate_connection => true
			# The path to our downloaded jdbc driver
			jdbc_driver_library => "/usr/share/logstash/postgresql-42.2.2.jar"
			# The name of the driver class for Postgresql
			jdbc_driver_class => "org.postgresql.Driver"
			# our query

			#statement => "SELECT id, created_date, last_modified, jurisdiction, case_type_id, state, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification from case_data where id=1"

			jdbc_paging_enabled => "true"
	    jdbc_page_size => "1000"

			statement => "SELECT id, created_date, last_modified, jurisdiction, case_type_id, state, data::TEXT as json_data, data_classification::TEXT as json_data_classification, reference, security_classification from case_data where last_modified > :sql_last_value::date"

    	clean_run => false
			# TODO if Logstash is recreated, we lose this. Shall we preserve this?
    	last_run_metadata_path => "/usr/share/logstash/data/.logstash_jdbc_last_run"
	    
	    # every second
			schedule => "* * * * * *"
	    # every 2 seconds
			# schedule => "/2 * * * * *"
    }
}

filter{
	json{
		source => "json_data"
		target => "data"
		remove_field => ["json_data"]
	}
	json{
		source => "json_data_classification"
		target => "data_classification"
		remove_field => ["json_data_classification"]
	}
	# mutate { remove_field => [ "@timestamp", "@version" ] }
	mutate {
    	add_field => { "index_id" => "%{case_type_id}_cases" }
  	}
	mutate {
		lowercase => [ "index_id" ]
	}
}

#FIXME document_type is deprecated
output {
    elasticsearch {
			hosts => ["10.112.0.4:9200"]
			sniffing => false
			index => "%{[index_id]}"
			document_type => "case"
			document_id => "%{id}"
    }
}
